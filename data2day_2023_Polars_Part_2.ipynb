{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvvEvKzsWboV"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bettercodepaul/data2day_2023_polars/blob/main/data2day_2023_Polars_Part_2.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "# Polars: The Turbo Boost for Dataframes - Part 2\n",
    "\n",
    "Important links as a reminder:\n",
    "\n",
    "- Homepage of Polars: https://www.pola.rs/\n",
    "- User Guide: https://pola-rs.github.io/polars/user-guide/\n",
    "- API Reference: https://pola-rs.github.io/polars/py-polars/html/reference/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EJKvLC6Z8ve"
   },
   "source": [
    "## Installation + Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJ39jUfNjscb"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IL4ogwh-eFM5",
    "outputId": "e4b623c6-7ffc-4785-d222-7c7559e5febf"
   },
   "outputs": [],
   "source": [
    "REQUIREMENTS_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/requirements.txt\"\n",
    "urllib.request.urlretrieve(REQUIREMENTS_URL, os.path.basename(REQUIREMENTS_URL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WH4yZSDm1rKj",
    "outputId": "8b2245ec-f31d-490a-fd19-a44c85969576"
   },
   "outputs": [],
   "source": [
    "# don't forget that you might need to restart the kernel\n",
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeCD6DDzkGYC"
   },
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NU9yjICo90O6",
    "outputId": "982b23fd-e81c-494e-9bfc-19f1b3a776f8"
   },
   "outputs": [],
   "source": [
    "# output up to 60 characters per column and do not abbreviate floating point numbers\n",
    "pl.Config(fmt_str_lengths=60, fmt_float=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV_0ZZgM16tU",
    "outputId": "4f150400-db52-4826-c1c3-44435bd8f2c9"
   },
   "outputs": [],
   "source": [
    "# download data\n",
    "DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
    "LOCAL_DATA_FILE_NAME = os.path.basename(DATA_URL)\n",
    "urllib.request.urlretrieve(DATA_URL, LOCAL_DATA_FILE_NAME)\n",
    "GENRES_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/track-genres.parquet\"\n",
    "LOCAL_GENRES_DATA_FILE_NAME = os.path.basename(GENRES_DATA_URL)\n",
    "urllib.request.urlretrieve(GENRES_DATA_URL, LOCAL_GENRES_DATA_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download excercises and utility functions\n",
    "EXERCISES_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/data2day_exercises_en.py\"\n",
    "urllib.request.urlretrieve(EXERCISES_URL, os.path.basename(EXERCISES_URL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data2day_exercises_en import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file and parse date columns\n",
    "df = pl.read_csv(\"spotify-charts-2017-2021-global-top200.csv.gz\", try_parse_dates=True)\n",
    "df.head(2) # output the first 2 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6SrEeCgd3D0"
   },
   "source": [
    "## Aggregations on groups\n",
    "\n",
    "In the first part you have already learned about aggregate functions like `max`, `min`, `mean` and `sum`. These functions become really powerful when you apply them to groups that you can form from almost any expression.\n",
    "\n",
    "The group is formed with the `group_by` method.\n",
    "\n",
    "The subsequent aggregation with the method `agg`. This method works similar to a `select`, but for aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the five most streamed artists\n",
    "(df\n",
    "    .group_by(\"artist\")\n",
    "    .agg(pl.col(\"streams\").sum())\n",
    "    .top_k(5, by=\"streams\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An aggregation can contain multiple expressions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the five most streamed artists and their average ranking in the charts\n",
    "(df\n",
    "    .group_by(\"artist\")\n",
    "    .agg(pl.col(\"streams\").sum(), pl.col(\"rank\").mean())\n",
    "    .top_k(5, by=\"streams\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grouping can also be done with multiple expressions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 5 most streamed artists in a year\n",
    "(df\n",
    "    .group_by(\"artist\", pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .agg(pl.col(\"streams\").sum())\n",
    "    .top_k(5, by=\"streams\")\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we are missing the year 2020! Fortunately, the function `head` also works on a grouped dataframe and then returns the first *n* rows per group. Disadvantage compared to `top_k`: we have to sort the dataset completely for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists with the most streams per year\n",
    "(df\n",
    "    .group_by(\"artist\", pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .agg(pl.col(\"streams\").sum())\n",
    "    .sort(\"streams\", descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check out which artists had the most numer of different songs in the top 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artists with the most number of different songs in the Top 200 per year\n",
    "(df\n",
    "    .group_by(\"artist\", pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .agg(pl.col(\"title\").n_unique().alias(\"distinctSongsInTop200\"))\n",
    "    .sort(\"distinctSongsInTop200\", descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would the rankings look like if you used the days at #1 as your benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artist with the most days at number 1 per year\n",
    "(df\n",
    "    .filter(pl.col(\"rank\").eq(1))\n",
    "    .group_by(\"artist\", pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .agg(pl.len().alias(\"daysOnNumberOne\"))\n",
    "    .sort(\"daysOnNumberOne\", descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of filtering the entire data set, we can even filter data in the aggregation\n",
    "(df\n",
    "    .group_by(\"artist\", pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .agg(\n",
    "        pl.col(\"streams\").sum(),\n",
    "        pl.col(\"date\").filter(pl.col(\"rank\").eq(1)).len().alias(\"daysOnNumberOne\")\n",
    "    )\n",
    "    .sort([\"daysOnNumberOne\", \"streams\"], descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more than one artist per line because we consider each collaboration as a separate artist. There are many well-known songs from such collaborations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_colabs = (df\n",
    "    .filter(pl.col(\"artist\").str.contains(\", \"))\n",
    "    .group_by(\"artist\", \"title\", \"url\")\n",
    "    .agg(pl.col(\"streams\").sum())\n",
    "    .top_k(5, by=\"streams\")\n",
    ")\n",
    "top_5_colabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_song(top_5_colabs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A special data type: lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars can also handle lists as a special data type very well. Such a list is created, for example, when we split a string with the method `str.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"artist\" as string\n",
    "df.filter(pl.col(\"artist\").eq(\"Shawn Mendes, Camila Cabello\")).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"artist\" as a list of strings\n",
    "(df\n",
    "    .filter(pl.col(\"artist\").eq(\"Shawn Mendes, Camila Cabello\"))\n",
    "    .head(1)\n",
    "    .with_columns(pl.col(\"artist\").str.split(\", \"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is sometimes very handy to roll out such lists with the `explode` method. This way the record is then duplicated accordingly often and can be treated like any other column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "    .filter(pl.col(\"artist\").eq(\"Shawn Mendes, Camila Cabello\"))\n",
    "    .head(1)\n",
    "    .with_columns(pl.col(\"artist\").str.split(\", \"))\n",
    "    .explode(\"artist\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute the artists with the most days at #1 without interpreting each collaboration as its own artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artists with most days on number 1 per year\n",
    "(df\n",
    "    .with_columns(pl.col(\"artist\").str.split(\", \"))\n",
    "    .explode(\"artist\")\n",
    "    .group_by(\"artist\", pl.col(\"date\").dt.year().alias(\"year\"))\n",
    "    .agg(\n",
    "        pl.col(\"streams\").sum(),\n",
    "        pl.col(\"date\").filter(pl.col(\"rank\").eq(1)).len().alias(\"daysOnNumberOne\")\n",
    "    )\n",
    "    .sort([\"daysOnNumberOne\", \"streams\"], descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of rolling out the lists, we can also work directly on list columns. Suitable method are in context `list`, e.g. `list.lengths()` for the length of a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many artists are there per top 200 entry?\n",
    "(df\n",
    "    .select(pl.col(\"artist\"))\n",
    "    .with_columns(pl.col(\"artist\").str.split(\", \"))\n",
    "    .with_columns(pl.col(\"artist\").list.lengths().alias(\"artistCount\"))\n",
    "    .group_by(\"artistCount\")\n",
    "    .len()\n",
    "    .sort(\"artistCount\")\n",
    "    .with_columns((pl.col(\"count\")/pl.col(\"count\").sum()).round(2).alias(\"percentage\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chart entry with 10 artists is \"Pa' La Cultura\" at #151 on 8/7/2020\n",
    "play_song(df\n",
    "    .with_columns(pl.col(\"artist\").str.split(\", \").list.lengths().alias(\"artistCount\"))\n",
    "    .filter(pl.col(\"artistCount\").eq(10))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises on groupings and aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q13.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q13_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q13.check(q13_df)\n",
    "#q13.hint()\n",
    "#q13.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q14.check(q14_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q15.check(q15_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joins & Co. - Connecting Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate with `pl.concat`\n",
    "A flexible and simple way to concatenate two data frames is the `pl.concat` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how=\"vertical\" stacks two dataframes on top of each other, names and types of columns must match\n",
    "pl.concat([\n",
    "    df.sample(1),\n",
    "    df.sample(1)\n",
    "], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how=\"vertical_relaxed\" tries to adjust the data types if necessary\n",
    "pl.concat([\n",
    "    df.sample(1),\n",
    "    df.sample(1).with_columns(pl.col(\"artist\").cast(pl.Categorical))\n",
    "], how=\"vertical_relaxed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how=\"diagonal\" can also handle other column names\n",
    "pl.concat([\n",
    "    df.sample(1).select(\"title\", \"artist\", pl.col(\"rank\").alias(\"position\")),\n",
    "    df.sample(1).select(\"title\", pl.col(\"artist\").alias(\"performer\"), \"rank\")\n",
    "], how=\"diagonal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how=\"horizontal\" puts dataframes side by side, the number of records must match\n",
    "some_df = df.sample(4)\n",
    "pl.concat([\n",
    "    some_df.select(\"title\", \"artist\"),\n",
    "    some_df.select(\"streams\", \"rank\")\n",
    "], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how=\"align\" puts dataframes side by side and tries to align them to the common key columns\n",
    "pl.concat([\n",
    "    some_df.sample(fraction=1.0, shuffle=True).select(\"url\", \"date\", \"title\"),\n",
    "    some_df.sample(fraction=1.0, shuffle=True).select(\"url\", \"date\", \"artist\"),\n",
    "    some_df.sample(fraction=0.5, shuffle=True).select(\"url\", \"date\", \"streams\")\n",
    "], how=\"align\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `how=align` actually already a join is performed, but it is not really clear on which columns.\n",
    "\n",
    "In most cases it will therefore be better to perform an explicit join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect mit `join`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joins allow us to connect two dataframes. Polars supports the following join types:\n",
    "\n",
    "`left.join(right, on=..., how=...)`.\n",
    "\n",
    "- `full`: all rows from `left` and `right`, even if they have no join partner in the other dataframe\n",
    "- `left`: all rows from `left`, even if they have no join partner in `right`.\n",
    "- `inner`: rows from `left` and `right` with matching join partner in the other dataframe\n",
    "- `semi`: rows from `left` with matching join partner in `right` (like `inner`, but no new columns from `right`)\n",
    "- `anti`: rows from `left` without matching join partner in `right` (opposite of `semi`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pl.DataFrame({\n",
    "    \"key\": [0, 1, 2],\n",
    "    \"value\": [\"a\", \"b\", \"c\"]\n",
    "})\n",
    "right = pl.DataFrame({\n",
    "    \"key\": [1, 2, 3],\n",
    "    \"value\": [\"x\", \"y\", \"z\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full outer join\n",
    "left.join(right, on=\"key\", how=\"full\").sort(\"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join\n",
    "left.join(right, on=\"key\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "left.join(right, on=\"key\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# semi join\n",
    "left.join(right, on=\"key\", how=\"semi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anti join\n",
    "left.join(right, on=\"key\", how=\"anti\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises on joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q16.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q16_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q16.check(q16_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q17.check(q17_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q18.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q18_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q18.check(q18_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping and Joining with Expressions: `over` Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many calculations, it can be helpful to evaluate an expression over a group.\n",
    "\n",
    "For example, we could try to determine the newcomer of the year. For this we need an information when an artist appeared in the charts for the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_appearance = df.group_by(\"artist\").agg(pl.col(\"date\").min().alias(\"firstChartAppearance\"))\n",
    "first_appearance.filter(pl.col(\"artist\").is_in([\"Billie Eilish\", \"Lewis Capaldi\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now join this new information to the overall data set to determine the Newcomer of the Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "    .join(first_appearance, on=\"artist\")\n",
    "    .filter(pl.col(\"date\").dt.year().eq(pl.col(\"firstChartAppearance\").dt.year()))\n",
    "    .group_by(pl.col(\"date\").dt.year().alias(\"year\"), \"artist\")\n",
    "    .agg(pl.col(\"streams\").sum())\n",
    "    .sort(\"streams\", descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ed Sheeran was no longer a newcomer in 2017, but we lack the informtions from previous years to do better....\n",
    "\n",
    "We can achieve the same without the intermediate data set by using an `over` expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    "    # expression with over instead of temporary dataframe with group_by, agg and join\n",
    "    .with_columns(pl.col(\"date\").min().over(\"artist\").alias(\"firstChartAppearance\"))\n",
    "    .filter(pl.col(\"date\").dt.year().eq(pl.col(\"firstChartAppearance\").dt.year()))\n",
    "    .group_by(pl.col(\"date\").dt.year().alias(\"year\"), \"artist\")\n",
    "    .agg(pl.col(\"streams\").sum())\n",
    "    .sort(\"streams\", descending=True)\n",
    "    .group_by(\"year\")\n",
    "    .head(1)\n",
    "    .sort(\"year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some calculations and especially plots it is helpful to switch between different variants of a dataframe.\n",
    "\n",
    "The Wide format has more columns (Wide) and less rows.\n",
    "The Long format has more rows (Long) and fewer columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_df = pl.DataFrame({\n",
    "    \"month\": [\"2023-01\", \"2023-01\", \"2023-01\", \"2023-02\"],\n",
    "    \"genre\": [\"pop\", \"rock\", \"hip-hop\", \"pop\"],\n",
    "    \"streams\": [100, 200, 300, 150] \n",
    "})\n",
    "some_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `pivot` method we can make a data set *wider*, i.e. transport information from rows to new columns. The following parameters are important:\n",
    "\n",
    "- `index`: columns that will be kept\n",
    "- `on`: column with values, from which new column names are formed\n",
    "- `values`: column with values, which are written into the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_df.pivot(index=\"month\", on=\"genre\", values=\"streams\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could replace the resulting `null` values with `fill_null`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_df.pivot(index=\"month\", on=\"genre\", values=\"streams\").fill_null(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the counterpart `unpivot` we can make a record longer again, i.e. transport information from columns to rows. The following parameters are important:\n",
    "\n",
    "- `index`: columns that are to be preserved\n",
    "- `on`: columns containing the values for the `value_name` column\n",
    "- `variable_name`: name of the column that should get the column names from `value_vars`.\n",
    "- `value_name`: name of the column that should get the values from the existing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(some_df\n",
    "    .pivot(index=\"month\", columns=\"genre\", values=\"streams\")\n",
    "    .unpivot(id_vars=\"month\", on=[\"pop\", \"rock\", \"hip-hop\"], variable_name=\"genre\", value_name=\"streams\")\n",
    "    .sort(\"month\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could remove the `null` values with `drop_nulls`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(some_df\n",
    "    .pivot(index=\"month\", columns=\"genre\", values=\"streams\")\n",
    "    .unpivot(id_vars=\"month\", on=[\"pop\", \"rock\", \"hip-hop\"], variable_name=\"genre\", value_name=\"streams\")\n",
    "    .sort(\"month\")\n",
    "    .drop_nulls()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selectors + horizontal expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Especially for data in \"wide\" format it is often helpful to perform operations on several columns without having to specify the column names specifically. In fact, sometimes the column names are not even known when a query is created, because they only emerge from the concrete data.\n",
    "\n",
    "So far we have always passed a single column name to `pl.col`, but there are more possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns by name\n",
    "df.select(pl.col(\"rank\", \"streams\").log()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns by data type\n",
    "df.select(pl.col(pl.Utf8).str.to_lowercase()).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns with a regular expression\n",
    "df.select(pl.col(\"^.*rt.*$\")).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, there is also the possibility to select all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.all()).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or even to exclude certain columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns, but not \"url\n",
    "df.select(pl.exclude(\"url\")).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all string columns, but not \"url\".\n",
    "df.select(pl.col(pl.Utf8).exclude(\"url\")).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On such a column selection, which contains more than one column, we can also perform \"horizontal\" calculations. For this purpose there are the methods `pl.horizontal_sum`, `pl.horizontal_min` and `pl.horizontal_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(pl.sum_horizontal(pl.exclude(pl.Utf8))).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q19.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q19_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q19.check(q19_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20.question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20_df = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q20.check(df, q20_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
