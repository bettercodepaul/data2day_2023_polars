{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvvEvKzsWboV"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bettercodepaul/data2day_2023_polars/blob/main/data2day_2023_Polars_Teil_3.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# Polars: Der Turbo Boost für Dataframes - Teil 3\n",
        "\n",
        "Wichtige Links zur Erinnerung:\n",
        "\n",
        "- Homepage von Polars: https://www.pola.rs/\n",
        "- User-Guide: https://pola-rs.github.io/polars/user-guide/\n",
        "- API-Referenz: https://pola-rs.github.io/polars/py-polars/html/reference/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJKvLC6Z8ve"
      },
      "source": [
        "## Installation + Vorbereitung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ39jUfNjscb"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL4ogwh-eFM5",
        "outputId": "e4b623c6-7ffc-4785-d222-7c7559e5febf"
      },
      "outputs": [],
      "source": [
        "REQUIREMENTS_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/requirements.txt\"\n",
        "urllib.request.urlretrieve(REQUIREMENTS_URL, os.path.basename(REQUIREMENTS_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4yZSDm1rKj",
        "outputId": "8b2245ec-f31d-490a-fd19-a44c85969576"
      },
      "outputs": [],
      "source": [
        "# nicht vergessen, dass die Laufzeitumgebung ggf. neu gestartet werden muss\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeCD6DDzkGYC"
      },
      "outputs": [],
      "source": [
        "import polars as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU9yjICo90O6",
        "outputId": "982b23fd-e81c-494e-9bfc-19f1b3a776f8"
      },
      "outputs": [],
      "source": [
        "# bis zu 60 Zeichen pro Spalte ausgeben und Fließkommazahlen nicht abkürzen\n",
        "pl.Config(fmt_str_lengths=60, fmt_float=\"full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV-Daten herunterladen\n",
        "CSV_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
        "LOCAL_CSV_DATA_FILE_NAME = os.path.basename(CSV_DATA_URL)\n",
        "urllib.request.urlretrieve(CSV_DATA_URL, LOCAL_CSV_DATA_FILE_NAME)\n",
        "REGION_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/region-info.csv\"\n",
        "LOCAL_REGION_DATA_FILE_NAME = os.path.basename(REGION_DATA_URL)\n",
        "urllib.request.urlretrieve(REGION_DATA_URL, LOCAL_REGION_DATA_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV_0ZZgM16tU",
        "outputId": "4f150400-db52-4826-c1c3-44435bd8f2c9"
      },
      "outputs": [],
      "source": [
        "# Parquet-Daten herunterladen\n",
        "BIG_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/releases/download/data-parquet/spotify-charts-2017-2021.parquet\"\n",
        "LOCAL_BIG_DATA_FILE_NAME = os.path.basename(BIG_DATA_URL)\n",
        "urllib.request.urlretrieve(BIG_DATA_URL, LOCAL_BIG_DATA_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Übungen und Hilfsfunktionen herunterladen\n",
        "EXERCISES_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/data2day_exercises.py\"\n",
        "urllib.request.urlretrieve(EXERCISES_URL, os.path.basename(EXERCISES_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data2day_exercises import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## When.Then.Otherwise\n",
        "\n",
        "Manchmal wollt ihr einen Ausdruck in bestimmten Fällen so und in anderen Fällen so berechnen.\n",
        "\n",
        "Dafür gibt es die Methoden `when.then.otherwise`, die einem `if.then.else` entsprechen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.read_csv(\"spotify-charts-2017-2021-global-top200.csv.gz\", try_parse_dates=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das funktioniert dann so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .with_columns(\n",
        "        pl.when(pl.col(\"date\").dt.day().eq(14) & pl.col(\"date\").dt.month().eq(2))\n",
        "        .then(pl.col(\"streams\"))\n",
        "        .otherwise(pl.lit(0))\n",
        "        .alias(\"valentinesStreams\")\n",
        "    )\n",
        "    .filter(pl.col(\"title\").eq(\"Starboy\") & pl.col(\"date\").dt.week().eq(7))\n",
        "    .select(\"date\", \"streams\", \"valentinesStreams\")\n",
        "    .head(5)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir könnten auch die Trend-Spalte selber nachstellen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .join(\n",
        "        # Position vom Vortag ermitteln\n",
        "        df.select(\"url\", pl.col(\"date\").dt.offset_by(\"1d\"), pl.col(\"rank\").alias(\"previous_rank\")),\n",
        "        how=\"left\",\n",
        "        on=[\"url\", \"date\"]\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.when(pl.col(\"rank\").lt(pl.col(\"previous_rank\")))\n",
        "        .then(pl.lit(\"MOVE_UP\"))\n",
        "        .otherwise(\n",
        "            pl.when(pl.col(\"rank\").gt(pl.col(\"previous_rank\")))\n",
        "            .then(pl.lit(\"MOVE_DOWN\"))\n",
        "            .otherwise(\n",
        "                pl.when(pl.col(\"rank\").eq(pl.col(\"previous_rank\")))\n",
        "                .then(pl.lit(\"SAME_POSITION\"))\n",
        "                .otherwise(pl.lit(\"NEW_ENTRY\"))\n",
        "            )\n",
        "        ).alias(\"myTrend\")\n",
        "    )\n",
        "    .select(\"title\", \"artist\", \"date\", \"trend\", \"myTrend\")\n",
        "    .sample(10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn es nur darum geht bestimmte, einzelne Werte mit anderen zu ersetzen, kann auch `map_dict` sehr praktisch sein."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    \"SAME_POSITION\": \"➡️\",\n",
        "    \"NEW_ENTRY\": \"🆕\",\n",
        "    \"MOVE_UP\": \"⬆️\",\n",
        "    \"MOVE_DOWN\": \"⬇️\"\n",
        "}\n",
        "(df\n",
        "  .with_columns(pl.col(\"trend\")\n",
        "  .map_dict(mapping).alias(\"trendSymbol\"))\n",
        "  .group_by(\"trendSymbol\")\n",
        "  .count()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bitte nicht: `map_*`\n",
        "\n",
        "Die denkbar schlechstes Möglichkeit eigene Funktionen in eine Polars-Abfrage einzuschmuggeln sind die verschiedenen map-Methoden `map_rows`, `map_batches`, `map_elements` und `map_groups`, die eine UDF (User Defined Function) ausführen.\n",
        "\n",
        "Das sollte vermieden werden, weil die Performance darunter sehr stark leidet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Expression Factories\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine elegantere Art & Weise zu modularem Code zu kommen, sind eigene Methoden, die neue Expressions erstellen und z.B. mit der `pipe` Methode aufgerufen werden können.\n",
        "\n",
        "Hier ein Beispiel für die Methode `sum` für die es in Polars keinen `min_count` Parameter gibt (den es aber in Pandas gibt). Der `min_count` Parameter bestimmt, wie viele Werte mindestens vorhanden sein müssen, damit die Summe gebildet wird."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sum(expr: pl.Expr, min_count=0) -> pl.Expr:\n",
        "    if min_count > 0:\n",
        "        return pl.when(\n",
        "            expr.is_not_null().sum().ge(pl.lit(min_count))\n",
        "        ).then(expr.sum())\n",
        "    else:\n",
        "        return expr.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.DataFrame({\n",
        "    \"value\": [42, 43, None], \n",
        "}).select(\n",
        "    pl.col(\"value\").pipe(sum, min_count=2).alias(\"min_count=2\"),\n",
        "    pl.col(\"value\").pipe(sum, min_count=3).alias(\"min_count=3\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir können solche Methoden auch in einem eigenen Namespace registrieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@pl.api.register_expr_namespace(\"special\")\n",
        "class Special:\n",
        "    def __init__(self, expr: pl.Expr):\n",
        "        self._expr = expr\n",
        "\n",
        "    def sum(self, min_count=0) -> pl.Expr:\n",
        "        if min_count > 0:\n",
        "            return pl.when(\n",
        "                self._expr.is_not_null().sum().ge(pl.lit(min_count))\n",
        "            ).then(self._expr.sum())\n",
        "        else:\n",
        "            return self._expr.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jetzt können wir die Methode innerhalb des eigenen Namespace \"special\" aufrufen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.DataFrame({\n",
        "    \"value\": [42, 43, None], \n",
        "}).select(\n",
        "    pl.col(\"value\").special.sum(min_count=2).alias(\"min_count=2\"),\n",
        "    pl.col(\"value\").special.sum(min_count=3).alias(\"min_count=3\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weiterführende Informationen gibt es hier:\n",
        "\n",
        "- [Expr.pipe](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.Expr.pipe.html)\n",
        "- [DataFrame.pipe](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.pipe.html)\n",
        "- [Extending the API](https://pola-rs.github.io/polars/py-polars/html/reference/api.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6SrEeCgd3D0"
      },
      "source": [
        "## Lazy vs. Eager\n",
        "\n",
        "Bis jetzt haben wir Polars immer im \"eager mode\" benutzt. Jeder Funktionsaufruf hatte direkt eine Operation auf den Daten zur Folge.\n",
        "\n",
        "Das hat Vorteile beim Debugging von Abfragen, verhindert aber viele Optimierungen, die Polars nur im \"lazy mode\" nutzen kann.\n",
        "\n",
        "Für den \"lazy mode\" gibt es zwei Optionen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eager Load + Lazy Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn ein Datensatz nicht zu groß ist, können wir ihn vollständig in den Speicher laden, wie wir es schon kennen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.read_csv(\"spotify-charts-2017-2021-global-top200.csv.gz\")\n",
        "type(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch den Aufruf der `lazy` Methode schalten wir dann in den \"lazy mode\". Die Ausführung der Abfrage ist jetzt angehalten und es wird mit jedem weiteren Aufruf nur die Abfrage \"formuliert\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lazy_df = df.lazy()\n",
        "type(lazy_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# für einen lazy Dataframe wird der unoptimierte Abfragebaum ausgegeben\n",
        "lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Plan wird von unten nach oben gelesen. Die griechischen Buchstaben sind aus der relationalen Algebra. Der Buchstabe π steht für die Operation Projektion (`select`), σ für die Operation Selektion (`filter`).\n",
        "\n",
        "- Table π */9; σ -; bedeutet, dass alle neun Spalten gelesen werden und keine Selektion vorgenommen wird\n",
        "- π 2/9 bedeutet, dass auf zwei von neun Spalten projiziert wird \n",
        "- FILTER BY ist die Selektion aus unserer Abfrage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mit der Methode show_graph() können wir die optimierte Abfrage ausgeben\n",
        "lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\")).show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sowohl die Projektion als auch die Selektion passieren im optimierten Abfrageplan früher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Abfrage wird letztendlich ausgeführt, wenn wir die Methode `collect` aufrufen. Das Ergebnis ist dann wieder ein normaler Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\")).collect()\n",
        "result.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch dieses Vorgehen, kann Polars Optimierungen vor der Ausführung der Abfrage vornehmen.\n",
        "\n",
        "Eine Auswahl an Optimierungen findet ihr hier: https://pola-rs.github.io/polars/user-guide/lazy/optimizations/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lazy Load + Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn es sich nicht lohnt einen Datensatz vollständig in den Speicher zu laden, können wir auch das Laden der Daten verzögern, in dem wir die IO-Methoden mit dem Namen `scan_*` statt `write_*` nutzen.\n",
        "\n",
        "Das funktioniert z.B. für Dateien in den Formaten CSV (`scan_csv`) und Parquet (`scan_parquet`), aber nicht für komprimierte CSVs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bisher haben wir immer mit einem kleinen Datensatz gearbeitet, der nur die globalen Top-200 Charts beinhaltet (362k Zeilen, 64 MB)\n",
        "\n",
        "Wir können jetzt auf den richtigen Datensatz wechseln, der die Top-200 und die Viral-50 Charts für 70 verschiedene Regionen enthält (26m Zeilen, 4 GB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch die optimierten Abfragen, werden nur die Daten aus der Datei geladen, die auch wirklich gebraucht werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .select(\"artist\", \"title\")\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ").show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Je nach Abfrage können bestimmte Optimierungen nicht durchgeführt werden, weil sie das  Ergebnis verändern würden..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .head(2)\n",
        "    .select(\"artist\", \"title\")\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ").show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manchmal lässt der Abfrage-Optimierer auch Potenzial liegen..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "naive_query = (df\n",
        "    .group_by(\"artist\")\n",
        "    .agg(pl.col(\"title\").n_unique())\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ")\n",
        "naive_query.show_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "naive_query.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir optimieren händisch, dass zuerst gefiltert werden sollte, was die Abfrage deutlich beschleunigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimized_query = (df\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        "    .group_by(\"artist\")\n",
        "    .agg(pl.col(\"title\").n_unique())\n",
        ")\n",
        "optimized_query.show_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "optimized_query.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Optimierer wird allerdings auch ständig weiterentwickelt. Siehe für diesen konkreten Fall z.B. https://github.com/pola-rs/polars/issues/11678"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streaming\n",
        "\n",
        "Wenn das Endergebnis oder auch Zwischenergebnisse einer Abfrage nicht mehr in den RAM passen, hat Polars einen \"streaming mode\", der den benötigten RAM deutlich senken kann.\n",
        "\n",
        "Wenn nur die Zwischen-Ergebnisse das Problem sind, kann der \"streaming mode\" mit `collect(streaming=True)` aktiviert werden. Das Endergebnis muss dann aber in den RAM passen.\n",
        "\n",
        "Um auch ein End-Ergebnis, das nicht mehr in den RAM passt, auf die Festplatte zu schreiben, können die Methoden `sink_parquet`, `sink_csv` und `sink_ipc` genutzt werden. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Falls der Jupyter-Kernel abgestürzt ist, neu starten und diese Zeile ausführen\n",
        "import polars as pl\n",
        "df = pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fraction ist der Anteil an Zeilen und beeinflusst den Speicherbedarf\n",
        "# 0.003 ~ 4 GB (sollte mit 8 GB RAM laufen)\n",
        "# 0.005 ~ 10 GB (sollte mit 16 GB RAM laufen)\n",
        "# 0.008 ~ 26 GB (sollte mit 32 GB RAM laufen)\n",
        "# 0.010 ~ 41 GB (sollte mit 64 GB RAM laufen)\n",
        "# 0.015 ~ 92 GB (sollte mit 128 GB RAM laufen)\n",
        "fraction = 0.008\n",
        "row_count = round(26173514*fraction)\n",
        "high_mem_query = (\n",
        "    df.head(row_count).join(df.head(row_count), on=\"artist\")\n",
        "    .filter(\n",
        "        pl.col(\"url\").ne(pl.col(\"url_right\")) &\n",
        "        pl.col(\"date\").gt(pl.col(\"date_right\")) &\n",
        "        pl.col(\"trend\").eq(\"NEW_ENTRY\") &\n",
        "        pl.col(\"trend_right\").eq(\"NEW_ENTRY\")\n",
        "    )\n",
        "    .group_by(\"url\").agg((pl.col(\"date\") - pl.col(\"date_right\")).min().alias(\"durationBetweenNewEntries\"))\n",
        "    .select(pl.col(\"durationBetweenNewEntries\").mean())\n",
        ")\n",
        "print(f\"Cross-product of {row_count:_} rows would contain {row_count**2:_} rows.\")\n",
        "print(f\"Estimated size for the intermediate join result is {6e-10*row_count**2:.2f} GB.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# probiere unterschiedliche Werte für \"fraction\" mit streaming=False und streaming=True\n",
        "high_mem_query.collect(streaming=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn eine Abfrage im Streaming-Modus ausgeführt werden kann, befindet sie sich innerhalb eines \"Pipeline\"-Knotens. Wenn einige Knoten nicht gestreamt werden können, werden sie außerhalb des \"Pipeline\"-Knotens angezeigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_mem_query.show_graph(streaming=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Übungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = (\n",
        "    pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")\n",
        "    .with_columns(pl.col(\"streams\").cast(pl.Int64))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q21.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q21_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q21.check(q21_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q22.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q22_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q22.check(q22_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q23.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q23_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q23.check(q23_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q24.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q24_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q24.check(q24_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q25.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "region_df = pl.scan_csv(\"region-info.csv\")\n",
        "xmasYears_per_continent = ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q25_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q25.check(q25_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
