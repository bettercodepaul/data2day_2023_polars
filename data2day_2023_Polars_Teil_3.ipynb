{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvvEvKzsWboV"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bettercodepaul/data2day_2023_polars/blob/main/data2day_2023_Polars_Teil_3.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# Polars: Der Turbo Boost f√ºr Dataframes - Teil 3\n",
        "\n",
        "Wichtige Links zur Erinnerung:\n",
        "\n",
        "- Homepage von Polars: https://www.pola.rs/\n",
        "- User-Guide: https://pola-rs.github.io/polars/user-guide/\n",
        "- API-Referenz: https://pola-rs.github.io/polars/py-polars/html/reference/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJKvLC6Z8ve"
      },
      "source": [
        "## Installation + Vorbereitung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ39jUfNjscb"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL4ogwh-eFM5",
        "outputId": "e4b623c6-7ffc-4785-d222-7c7559e5febf"
      },
      "outputs": [],
      "source": [
        "REQUIREMENTS_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/requirements.txt\"\n",
        "urllib.request.urlretrieve(REQUIREMENTS_URL, os.path.basename(REQUIREMENTS_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4yZSDm1rKj",
        "outputId": "8b2245ec-f31d-490a-fd19-a44c85969576"
      },
      "outputs": [],
      "source": [
        "# nicht vergessen, dass die Laufzeitumgebung ggf. neu gestartet werden muss\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeCD6DDzkGYC"
      },
      "outputs": [],
      "source": [
        "import polars as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU9yjICo90O6",
        "outputId": "982b23fd-e81c-494e-9bfc-19f1b3a776f8"
      },
      "outputs": [],
      "source": [
        "# bis zu 60 Zeichen pro Spalte ausgeben und Flie√ükommazahlen nicht abk√ºrzen\n",
        "pl.Config(fmt_str_lengths=60, fmt_float=\"full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV-Daten herunterladen\n",
        "CSV_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
        "LOCAL_CSV_DATA_FILE_NAME = os.path.basename(CSV_DATA_URL)\n",
        "urllib.request.urlretrieve(CSV_DATA_URL, LOCAL_CSV_DATA_FILE_NAME)\n",
        "REGION_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/region-info.csv\"\n",
        "LOCAL_REGION_DATA_FILE_NAME = os.path.basename(REGION_DATA_URL)\n",
        "urllib.request.urlretrieve(REGION_DATA_URL, LOCAL_REGION_DATA_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV_0ZZgM16tU",
        "outputId": "4f150400-db52-4826-c1c3-44435bd8f2c9"
      },
      "outputs": [],
      "source": [
        "# Parquet-Daten herunterladen\n",
        "BIG_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/releases/download/data-parquet/spotify-charts-2017-2021.parquet\"\n",
        "LOCAL_BIG_DATA_FILE_NAME = os.path.basename(BIG_DATA_URL)\n",
        "urllib.request.urlretrieve(BIG_DATA_URL, LOCAL_BIG_DATA_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# √úbungen und Hilfsfunktionen herunterladen\n",
        "EXERCISES_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/data2day_exercises.py\"\n",
        "urllib.request.urlretrieve(EXERCISES_URL, os.path.basename(EXERCISES_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data2day_exercises import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## When.Then.Otherwise\n",
        "\n",
        "Manchmal wollt ihr einen Ausdruck in bestimmten F√§llen so und in anderen F√§llen so berechnen.\n",
        "\n",
        "Daf√ºr gibt es die Methoden `when.then.otherwise`, die einem `if.then.else` entsprechen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.read_csv(\"spotify-charts-2017-2021-global-top200.csv.gz\", try_parse_dates=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Das funktioniert dann so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .with_columns(\n",
        "        pl.when(pl.col(\"date\").dt.day().eq(14) & pl.col(\"date\").dt.month().eq(2))\n",
        "        .then(pl.col(\"streams\"))\n",
        "        .otherwise(pl.lit(0))\n",
        "        .alias(\"valentinesStreams\")\n",
        "    )\n",
        "    .filter(pl.col(\"title\").eq(\"Starboy\") & pl.col(\"date\").dt.week().eq(7))\n",
        "    .select(\"date\", \"streams\", \"valentinesStreams\")\n",
        "    .head(5)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir k√∂nnten auch die Trend-Spalte selber nachstellen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .join(\n",
        "        # Position vom Vortag ermitteln\n",
        "        df.select(\"url\", pl.col(\"date\").dt.offset_by(\"1d\"), pl.col(\"rank\").alias(\"previous_rank\")),\n",
        "        how=\"left\",\n",
        "        on=[\"url\", \"date\"]\n",
        "    )\n",
        "    .with_columns(\n",
        "        pl.when(pl.col(\"rank\").lt(pl.col(\"previous_rank\")))\n",
        "        .then(pl.lit(\"MOVE_UP\"))\n",
        "        .otherwise(\n",
        "            pl.when(pl.col(\"rank\").gt(pl.col(\"previous_rank\")))\n",
        "            .then(pl.lit(\"MOVE_DOWN\"))\n",
        "            .otherwise(\n",
        "                pl.when(pl.col(\"rank\").eq(pl.col(\"previous_rank\")))\n",
        "                .then(pl.lit(\"SAME_POSITION\"))\n",
        "                .otherwise(pl.lit(\"NEW_ENTRY\"))\n",
        "            )\n",
        "        ).alias(\"myTrend\")\n",
        "    )\n",
        "    .select(\"title\", \"artist\", \"date\", \"trend\", \"myTrend\")\n",
        "    .sample(10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn es nur darum geht bestimmte, einzelne Werte mit anderen zu ersetzen, kann auch `map_dict` sehr praktisch sein."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mapping = {\n",
        "    \"SAME_POSITION\": \"‚û°Ô∏è\",\n",
        "    \"NEW_ENTRY\": \"üÜï\",\n",
        "    \"MOVE_UP\": \"‚¨ÜÔ∏è\",\n",
        "    \"MOVE_DOWN\": \"‚¨áÔ∏è\"\n",
        "}\n",
        "(df\n",
        "  .with_columns(pl.col(\"trend\")\n",
        "  .map_dict(mapping).alias(\"trendSymbol\"))\n",
        "  .group_by(\"trendSymbol\")\n",
        "  .count()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bitte nicht: `map_*`\n",
        "\n",
        "Die denkbar schlechstes M√∂glichkeit eigene Funktionen in eine Polars-Abfrage einzuschmuggeln sind die verschiedenen map-Methoden `map_rows`, `map_batches`, `map_elements` und `map_groups`, die eine UDF (User Defined Function) ausf√ºhren.\n",
        "\n",
        "Das sollte vermieden werden, weil die Performance darunter sehr stark leidet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Expression Factories\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Eine elegantere Art & Weise zu modularem Code zu kommen, sind eigene Methoden, die neue Expressions erstellen und z.B. mit der `pipe` Methode aufgerufen werden k√∂nnen.\n",
        "\n",
        "Hier ein Beispiel f√ºr die Methode `sum` f√ºr die es in Polars keinen `min_count` Parameter gibt (den es aber in Pandas gibt). Der `min_count` Parameter bestimmt, wie viele Werte mindestens vorhanden sein m√ºssen, damit die Summe gebildet wird."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sum(expr: pl.Expr, min_count=0) -> pl.Expr:\n",
        "    if min_count > 0:\n",
        "        return pl.when(\n",
        "            expr.is_not_null().sum().ge(pl.lit(min_count))\n",
        "        ).then(expr.sum())\n",
        "    else:\n",
        "        return expr.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.DataFrame({\n",
        "    \"value\": [42, 43, None], \n",
        "}).select(\n",
        "    pl.col(\"value\").pipe(sum, min_count=2).alias(\"min_count=2\"),\n",
        "    pl.col(\"value\").pipe(sum, min_count=3).alias(\"min_count=3\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir k√∂nnen solche Methoden auch in einem eigenen Namespace registrieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@pl.api.register_expr_namespace(\"special\")\n",
        "class Special:\n",
        "    def __init__(self, expr: pl.Expr):\n",
        "        self._expr = expr\n",
        "\n",
        "    def sum(self, min_count=0) -> pl.Expr:\n",
        "        if min_count > 0:\n",
        "            return pl.when(\n",
        "                self._expr.is_not_null().sum().ge(pl.lit(min_count))\n",
        "            ).then(self._expr.sum())\n",
        "        else:\n",
        "            return self._expr.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jetzt k√∂nnen wir die Methode innerhalb des eigenen Namespace \"special\" aufrufen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pl.DataFrame({\n",
        "    \"value\": [42, 43, None], \n",
        "}).select(\n",
        "    pl.col(\"value\").special.sum(min_count=2).alias(\"min_count=2\"),\n",
        "    pl.col(\"value\").special.sum(min_count=3).alias(\"min_count=3\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weiterf√ºhrende Informationen gibt es hier:\n",
        "\n",
        "- [Expr.pipe](https://pola-rs.github.io/polars/py-polars/html/reference/expressions/api/polars.Expr.pipe.html)\n",
        "- [DataFrame.pipe](https://pola-rs.github.io/polars/py-polars/html/reference/dataframe/api/polars.DataFrame.pipe.html)\n",
        "- [Extending the API](https://pola-rs.github.io/polars/py-polars/html/reference/api.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6SrEeCgd3D0"
      },
      "source": [
        "## Lazy vs. Eager\n",
        "\n",
        "Bis jetzt haben wir Polars immer im \"eager mode\" benutzt. Jeder Funktionsaufruf hatte direkt eine Operation auf den Daten zur Folge.\n",
        "\n",
        "Das hat Vorteile beim Debugging von Abfragen, verhindert aber viele Optimierungen, die Polars nur im \"lazy mode\" nutzen kann.\n",
        "\n",
        "F√ºr den \"lazy mode\" gibt es zwei Optionen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eager Load + Lazy Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn ein Datensatz nicht zu gro√ü ist, k√∂nnen wir ihn vollst√§ndig in den Speicher laden, wie wir es schon kennen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.read_csv(\"spotify-charts-2017-2021-global-top200.csv.gz\")\n",
        "type(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch den Aufruf der `lazy` Methode schalten wir dann in den \"lazy mode\". Die Ausf√ºhrung der Abfrage ist jetzt angehalten und es wird mit jedem weiteren Aufruf nur die Abfrage \"formuliert\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lazy_df = df.lazy()\n",
        "type(lazy_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# f√ºr einen lazy Dataframe wird der unoptimierte Abfragebaum ausgegeben\n",
        "lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Plan wird von unten nach oben gelesen. Die griechischen Buchstaben sind aus der relationalen Algebra. Der Buchstabe œÄ steht f√ºr die Operation Projektion (`select`), œÉ f√ºr die Operation Selektion (`filter`).\n",
        "\n",
        "- Table œÄ */9; œÉ -; bedeutet, dass alle neun Spalten gelesen werden und keine Selektion vorgenommen wird\n",
        "- œÄ 2/9 bedeutet, dass auf zwei von neun Spalten projiziert wird \n",
        "- FILTER BY ist die Selektion aus unserer Abfrage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mit der Methode show_graph() k√∂nnen wir die optimierte Abfrage ausgeben\n",
        "lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\")).show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sowohl die Projektion als auch die Selektion passieren im optimierten Abfrageplan fr√ºher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Abfrage wird letztendlich ausgef√ºhrt, wenn wir die Methode `collect` aufrufen. Das Ergebnis ist dann wieder ein normaler Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\")).collect()\n",
        "result.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch dieses Vorgehen, kann Polars Optimierungen vor der Ausf√ºhrung der Abfrage vornehmen.\n",
        "\n",
        "Eine Auswahl an Optimierungen findet ihr hier: https://pola-rs.github.io/polars/user-guide/lazy/optimizations/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lazy Load + Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn es sich nicht lohnt einen Datensatz vollst√§ndig in den Speicher zu laden, k√∂nnen wir auch das Laden der Daten verz√∂gern, in dem wir die IO-Methoden mit dem Namen `scan_*` statt `write_*` nutzen.\n",
        "\n",
        "Das funktioniert z.B. f√ºr Dateien in den Formaten CSV (`scan_csv`) und Parquet (`scan_parquet`), aber nicht f√ºr komprimierte CSVs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bisher haben wir immer mit einem kleinen Datensatz gearbeitet, der nur die globalen Top-200 Charts beinhaltet (362k Zeilen, 64 MB)\n",
        "\n",
        "Wir k√∂nnen jetzt auf den richtigen Datensatz wechseln, der die Top-200 und die Viral-50 Charts f√ºr 70 verschiedene Regionen enth√§lt (26m Zeilen, 4 GB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch die optimierten Abfragen, werden nur die Daten aus der Datei geladen, die auch wirklich gebraucht werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .select(\"artist\", \"title\")\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ").show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Je nach Abfrage k√∂nnen bestimmte Optimierungen nicht durchgef√ºhrt werden, weil sie das  Ergebnis ver√§ndern w√ºrden..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .head(2)\n",
        "    .select(\"artist\", \"title\")\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ").show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manchmal l√§sst der Abfrage-Optimierer auch Potenzial liegen..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "naive_query = (df\n",
        "    .group_by(\"artist\")\n",
        "    .agg(pl.col(\"title\").n_unique())\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ")\n",
        "naive_query.show_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "naive_query.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir optimieren h√§ndisch, dass zuerst gefiltert werden sollte, was die Abfrage deutlich beschleunigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimized_query = (df\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        "    .group_by(\"artist\")\n",
        "    .agg(pl.col(\"title\").n_unique())\n",
        ")\n",
        "optimized_query.show_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "optimized_query.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Optimierer wird allerdings auch st√§ndig weiterentwickelt. Siehe f√ºr diesen konkreten Fall z.B. https://github.com/pola-rs/polars/issues/11678"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streaming\n",
        "\n",
        "Wenn das Endergebnis oder auch Zwischenergebnisse einer Abfrage nicht mehr in den RAM passen, hat Polars einen \"streaming mode\", der den ben√∂tigten RAM deutlich senken kann.\n",
        "\n",
        "Wenn nur die Zwischen-Ergebnisse das Problem sind, kann der \"streaming mode\" mit `collect(streaming=True)` aktiviert werden. Das Endergebnis muss dann aber in den RAM passen.\n",
        "\n",
        "Um auch ein End-Ergebnis, das nicht mehr in den RAM passt, auf die Festplatte zu schreiben, k√∂nnen die Methoden `sink_parquet`, `sink_csv` und `sink_ipc` genutzt werden. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Falls der Jupyter-Kernel abgest√ºrzt ist, neu starten und diese Zeile ausf√ºhren\n",
        "import polars as pl\n",
        "df = pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fraction ist der Anteil an Zeilen und beeinflusst den Speicherbedarf\n",
        "# 0.003 ~ 4 GB (sollte mit 8 GB RAM laufen)\n",
        "# 0.005 ~ 10 GB (sollte mit 16 GB RAM laufen)\n",
        "# 0.008 ~ 26 GB (sollte mit 32 GB RAM laufen)\n",
        "# 0.010 ~ 41 GB (sollte mit 64 GB RAM laufen)\n",
        "# 0.015 ~ 92 GB (sollte mit 128 GB RAM laufen)\n",
        "fraction = 0.008\n",
        "row_count = round(26173514*fraction)\n",
        "high_mem_query = (\n",
        "    df.head(row_count).join(df.head(row_count), on=\"artist\")\n",
        "    .filter(\n",
        "        pl.col(\"url\").ne(pl.col(\"url_right\")) &\n",
        "        pl.col(\"date\").gt(pl.col(\"date_right\")) &\n",
        "        pl.col(\"trend\").eq(\"NEW_ENTRY\") &\n",
        "        pl.col(\"trend_right\").eq(\"NEW_ENTRY\")\n",
        "    )\n",
        "    .group_by(\"url\").agg((pl.col(\"date\") - pl.col(\"date_right\")).min().alias(\"durationBetweenNewEntries\"))\n",
        "    .select(pl.col(\"durationBetweenNewEntries\").mean())\n",
        ")\n",
        "print(f\"Cross-product of {row_count:_} rows would contain {row_count**2:_} rows.\")\n",
        "print(f\"Estimated size for the intermediate join result is {6e-10*row_count**2:.2f} GB.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# probiere unterschiedliche Werte f√ºr \"fraction\" mit streaming=False und streaming=True\n",
        "high_mem_query.collect(streaming=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn eine Abfrage im Streaming-Modus ausgef√ºhrt werden kann, befindet sie sich innerhalb eines \"Pipeline\"-Knotens. Wenn einige Knoten nicht gestreamt werden k√∂nnen, werden sie au√üerhalb des \"Pipeline\"-Knotens angezeigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_mem_query.show_graph(streaming=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## √úbungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = (\n",
        "    pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")\n",
        "    .with_columns(pl.col(\"streams\").cast(pl.Int64))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q21.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q21_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q21.check(q21_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q22.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q22_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q22.check(q22_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 23"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q23.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q23_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q23.check(q23_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q24.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q24_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q24.check(q24_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Frage 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q25.question()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "region_df = pl.scan_csv(\"region-info.csv\")\n",
        "xmasYears_per_continent = ...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q25_df = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "q25.check(q25_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
