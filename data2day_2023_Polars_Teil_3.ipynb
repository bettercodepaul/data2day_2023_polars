{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvvEvKzsWboV"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/datenzauberai/data2day_2023_polars/blob/main/data2day_2023_Polars_Teil_1.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# Polars: Der Turbo Boost für Dataframes - Teil 3\n",
        "\n",
        "Wichtige Links zur Erinnerung:\n",
        "\n",
        "- Homepage von Polars: https://www.pola.rs/\n",
        "- User-Guide: https://pola-rs.github.io/polars/user-guide/\n",
        "- API-Referenz: https://pola-rs.github.io/polars/py-polars/html/reference/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EJKvLC6Z8ve"
      },
      "source": [
        "## Installation + Vorbereitung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ39jUfNjscb"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL4ogwh-eFM5",
        "outputId": "e4b623c6-7ffc-4785-d222-7c7559e5febf"
      },
      "outputs": [],
      "source": [
        "REQUIREMENTS_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/requirements.txt\"\n",
        "urllib.request.urlretrieve(REQUIREMENTS_URL, os.path.basename(REQUIREMENTS_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4yZSDm1rKj",
        "outputId": "8b2245ec-f31d-490a-fd19-a44c85969576"
      },
      "outputs": [],
      "source": [
        "# nicht vergessen, dass die Laufzeitumgebung ggf. neu gestartet werden muss\n",
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeCD6DDzkGYC"
      },
      "outputs": [],
      "source": [
        "import polars as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NU9yjICo90O6",
        "outputId": "982b23fd-e81c-494e-9bfc-19f1b3a776f8"
      },
      "outputs": [],
      "source": [
        "# bis zu 60 Zeichen pro Spalte ausgeben und Fließkommazahlen nicht abkürzen\n",
        "pl.Config(fmt_str_lengths=60, fmt_float=\"full\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV-Daten herunterladen\n",
        "CSV_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/spotify-charts-2017-2021-global-top200.csv.gz\"\n",
        "LOCAL_CSV_DATA_FILE_NAME = os.path.basename(CSV_DATA_URL)\n",
        "urllib.request.urlretrieve(CSV_DATA_URL, LOCAL_CSV_DATA_FILE_NAME)\n",
        "REGION_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/region-info.csv\"\n",
        "LOCAL_REGION_DATA_FILE_NAME = os.path.basename(REGION_DATA_URL)\n",
        "urllib.request.urlretrieve(REGION_DATA_URL, LOCAL_REGION_DATA_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV_0ZZgM16tU",
        "outputId": "4f150400-db52-4826-c1c3-44435bd8f2c9"
      },
      "outputs": [],
      "source": [
        "# Parquet-Daten herunterladen\n",
        "BIG_DATA_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/releases/download/data-parquet/spotify-charts-2017-2021.parquet\"\n",
        "LOCAL_BIG_DATA_FILE_NAME = os.path.basename(BIG_DATA_URL)\n",
        "urllib.request.urlretrieve(BIG_DATA_URL, LOCAL_BIG_DATA_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Übungen und Hilfsfunktionen herunterladen\n",
        "EXERCISES_URL = \"https://github.com/bettercodepaul/data2day_2023_polars/raw/main/data2day_exercises.py\"\n",
        "urllib.request.urlretrieve(EXERCISES_URL, os.path.basename(EXERCISES_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data2day_exercises import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bitte nicht: `map_*`\n",
        "\n",
        "Die denkbar schlechstes Möglichkeit eigene Funktionen in eine Polars-Abfrage einzuschmuggeln sind die verschiedenen map-Methoden `map_rows`, `map_batches`, `map_elements` und `map_groups`, die eine UDF (User Defined Function) ausführen.\n",
        "\n",
        "Das sollte vermieden werden, weil die Performance darunter sehr stark leidet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Expression Factories\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6SrEeCgd3D0"
      },
      "source": [
        "## Lazy vs. Eager\n",
        "\n",
        "Bis jetzt haben wir Polars immer im \"eager mode\" benutzt. Jeder Funktionsaufruf hatte direkt eine Operation auf den Daten zur Folge.\n",
        "\n",
        "Das hat Vorteile beim Debugging von Abfragen, verhindert aber viele Optimierungen, die Polars nur im \"lazy mode\" nutzen kann.\n",
        "\n",
        "Für den \"lazy mode\" gibt es zwei Optionen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Eager Load + Lazy Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn ein Datensatz nicht zu groß ist, können wir ihn vollständig in den Speicher laden, wie wir es schon kennen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.read_csv(\"spotify-charts-2017-2021-global-top200.csv.gz\")\n",
        "type(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch den Aufruf der `lazy` Methode schalten wir dann in den \"lazy mode\". Die Ausführung der Abfrage ist jetzt angehalten und es wird mit jedem weiteren Aufruf nur die Abfrage \"formuliert\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lazy_df = df.lazy()\n",
        "type(lazy_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# für einen lazy Dataframe wird der unoptimierte Abfragebaum ausgegeben\n",
        "lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Plan wird von unten nach oben gelesen. Die griechischen Buchstaben sind aus der relationalen Algebra. Der Buchstabe π steht für die Operation Projektion (`select`), σ für die Operation Selektion (`filter`).\n",
        "\n",
        "- Table π */9; σ -; bedeutet, dass alle neun Spalten gelesen werden und keine Selektion vorgenommen wird\n",
        "- π 2/9 bedeutet, dass auf zwei von neun Spalten projiziert wird \n",
        "- FILTER BY ist die Selektion aus unserer Abfrage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mit der Methode show_graph() können wir die optimierte Abfrage ausgeben\n",
        "lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\")).show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sowohl die Projektion als auch die Selektion passieren im optimierten Abfrageplan früher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Die Abfrage wird letztendlich ausgeführt, wenn wir die Methode `collect` aufrufen. Das Ergebnis ist dann wieder ein normaler Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = lazy_df.select(\"artist\", \"title\").filter(pl.col(\"artist\").eq(\"Dua Lipa\")).collect()\n",
        "result.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "type(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch dieses Vorgehen, kann Polars Optimierungen vor der Ausführung der Abfrage vornehmen.\n",
        "\n",
        "Eine Auswahl an Optimierungen findet ihr hier: https://pola-rs.github.io/polars/user-guide/lazy/optimizations/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lazy Load + Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wenn es sich nicht lohnt einen Datensatz vollständig in den Speicher zu laden, können wir auch das Laden der Daten verzögern, in dem wir die IO-Methoden mit dem Namen `scan_*` statt `write_*` nutzen.\n",
        "\n",
        "Das funktioniert z.B. für Dateien in den Formaten CSV (`scan_csv`) und Parquet (`scan_parquet`), aber nicht für komprimierte CSVs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bisher haben wir immer mit einem kleinen Datensatz gearbeitet, der nur die globalen Top-200 Charts beinhaltet (362k Zeilen, 64 MB)\n",
        "\n",
        "Wir können jetzt auf den richtigen Datensatz wechseln, der die Top-200 und die Viral-50 Charts für 70 verschiedene Regionen enthält (26m Zeilen, 4 GB)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Durch die optimierten Abfragen, werden nur die Daten aus der Datei geladen, die auch wirklich gebraucht werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .select(\"artist\", \"title\")\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ").show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Je nach Abfrage können bestimmte Optimierungen nicht durchgeführt werden, weil sie das  Ergebnis verändern würden..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(df\n",
        "    .head(2)\n",
        "    .select(\"artist\", \"title\")\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ").show_graph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manchmal lässt der Abfrage-Optimierer auch Potenzial liegen..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "naive_query = (df\n",
        "    .group_by(\"artist\")\n",
        "    .agg(pl.col(\"title\").n_unique())\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        ")\n",
        "naive_query.show_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "naive_query.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wir optimieren händisch, dass zuerst gefiltert werden sollte, was die Abfrage deutlich beschleunigt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimized_query = (df\n",
        "    .filter(pl.col(\"artist\").eq(\"Dua Lipa\"))\n",
        "    .group_by(\"artist\")\n",
        "    .agg(pl.col(\"title\").n_unique())\n",
        ")\n",
        "optimized_query.show_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%timeit\n",
        "optimized_query.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Der Optimierer wird allerdings auch ständig weiterentwickelt. Siehe für diesen konkreten Fall z.B. https://github.com/pola-rs/polars/issues/11678"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Streaming\n",
        "\n",
        "Wenn das Endergebnis oder auch Zwischenergebnisse einer Abfrage nicht mehr in den RAM passen, hat Polars einen \"streaming mode\", der den benötigten RAM deutlich senken kann.\n",
        "\n",
        "Wenn nur die Zwischen-Ergebnisse das Problem sind, kann der \"streaming mode\" mit `collect(streaming=True)` aktiviert werden. Das Endergebnis muss dann aber in den RAM passen.\n",
        "\n",
        "Um auch ein End-Ergebnis, das nicht mehr in den RAM passt, auf die Festplatte zu schreiben, können die Methoden `sink_parquet`, `sink_csv` und `sink_ipc` genutzt werden. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Falls der Jupyter-Kernel abgestürzt ist, neu starten und diese Zeile ausführen\n",
        "import polars as pl\n",
        "df = pl.scan_parquet(\"spotify-charts-2017-2021.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-product of 209_388 rows would contain 43_843_334_544 rows.\n",
            "Estimated size for the intermediate join result is 26.31 GB.\n"
          ]
        }
      ],
      "source": [
        "# fraction ist der Anteil an Zeilen und beeinflusst den Speicherbedarf\n",
        "# 0.003 ~ 4 GB (sollte mit 8 GB RAM laufen)\n",
        "# 0.005 ~ 10 GB (sollte mit 16 GB RAM laufen)\n",
        "# 0.008 ~ 26 GB (sollte mit 32 GB RAM laufen)\n",
        "# 0.010 ~ 41 GB (sollte mit 64 GB RAM laufen)\n",
        "# 0.015 ~ 92 GB (sollte mit 128 GB RAM laufen)\n",
        "fraction = 0.008\n",
        "row_count = round(26173514*fraction)\n",
        "high_mem_query = (\n",
        "    df.head(row_count).join(df.head(row_count), on=\"artist\")\n",
        "    .filter(\n",
        "        pl.col(\"url\").ne(pl.col(\"url_right\")) &\n",
        "        pl.col(\"date\").gt(pl.col(\"date_right\")) &\n",
        "        pl.col(\"trend\").eq(\"NEW_ENTRY\") &\n",
        "        pl.col(\"trend_right\").eq(\"NEW_ENTRY\")\n",
        "    )\n",
        "    .group_by(\"url\").agg((pl.col(\"date\") - pl.col(\"date_right\")).min().alias(\"durationBetweenNewEntries\"))\n",
        "    .select(pl.col(\"durationBetweenNewEntries\").mean())\n",
        ")\n",
        "print(f\"Cross-product of {row_count:_} rows would contain {row_count**2:_} rows.\")\n",
        "print(f\"Estimated size for the intermediate join result is {6e-10*row_count**2:.2f} GB.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><style>\n",
              ".dataframe > thead > tr > th,\n",
              ".dataframe > tbody > tr > td {\n",
              "  text-align: right;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<small>shape: (1, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>durationBetweenNewEntries</th></tr><tr><td>duration[ms]</td></tr></thead><tbody><tr><td>101d 5h 23m 10s 201ms</td></tr></tbody></table></div>"
            ],
            "text/plain": [
              "shape: (1, 1)\n",
              "┌───────────────────────────┐\n",
              "│ durationBetweenNewEntries │\n",
              "│ ---                       │\n",
              "│ duration[ms]              │\n",
              "╞═══════════════════════════╡\n",
              "│ 101d 5h 23m 10s 201ms     │\n",
              "└───────────────────────────┘"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# streaming=False \n",
        "high_mem_query.collect(streaming=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_mem_query.show_graph(streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
